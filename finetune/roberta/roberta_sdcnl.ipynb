{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-26T15:12:11.398559Z",
     "iopub.status.busy": "2024-12-26T15:12:11.398270Z",
     "iopub.status.idle": "2024-12-26T15:12:26.514211Z",
     "shell.execute_reply": "2024-12-26T15:12:26.513574Z",
     "shell.execute_reply.started": "2024-12-26T15:12:11.398536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import multiprocessing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:12:32.737941Z",
     "iopub.status.busy": "2024-12-26T15:12:32.737620Z",
     "iopub.status.idle": "2024-12-26T15:12:32.743870Z",
     "shell.execute_reply": "2024-12-26T15:12:32.743250Z",
     "shell.execute_reply.started": "2024-12-26T15:12:32.737913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:12:34.630930Z",
     "iopub.status.busy": "2024-12-26T15:12:34.630632Z",
     "iopub.status.idle": "2024-12-26T15:12:34.634503Z",
     "shell.execute_reply": "2024-12-26T15:12:34.633705Z",
     "shell.execute_reply.started": "2024-12-26T15:12:34.630906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "multiprocessing.set_start_method(\"spawn\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:12:36.449782Z",
     "iopub.status.busy": "2024-12-26T15:12:36.449480Z",
     "iopub.status.idle": "2024-12-26T15:12:42.738815Z",
     "shell.execute_reply": "2024-12-26T15:12:42.738162Z",
     "shell.execute_reply.started": "2024-12-26T15:12:36.449756Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchallesvu\u001b[0m (\u001b[33mchallesvu-ton-duc-thang-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"c62c25918ce7fcb2ae41fc887c02e43aeb0cb261\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:12:44.318895Z",
     "iopub.status.busy": "2024-12-26T15:12:44.318287Z",
     "iopub.status.idle": "2024-12-26T15:12:44.322544Z",
     "shell.execute_reply": "2024-12-26T15:12:44.321821Z",
     "shell.execute_reply.started": "2024-12-26T15:12:44.318863Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:12:46.462472Z",
     "iopub.status.busy": "2024-12-26T15:12:46.462197Z",
     "iopub.status.idle": "2024-12-26T15:12:46.504652Z",
     "shell.execute_reply": "2024-12-26T15:12:46.504041Z",
     "shell.execute_reply.started": "2024-12-26T15:12:46.462450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = load_data('/kaggle/input/mental-datasets/SDCNL/train.csv')\n",
    "val_data = load_data('/kaggle/input/mental-datasets/SDCNL/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:12:48.349434Z",
     "iopub.status.busy": "2024-12-26T15:12:48.349154Z",
     "iopub.status.idle": "2024-12-26T15:12:48.354595Z",
     "shell.execute_reply": "2024-12-26T15:12:48.353830Z",
     "shell.execute_reply.started": "2024-12-26T15:12:48.349412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class sDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:12:50.386727Z",
     "iopub.status.busy": "2024-12-26T15:12:50.386437Z",
     "iopub.status.idle": "2024-12-26T15:12:57.245482Z",
     "shell.execute_reply": "2024-12-26T15:12:57.244867Z",
     "shell.execute_reply.started": "2024-12-26T15:12:50.386701Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553264dbe1b34166841e0d17f5dbb209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ee24972af64e3a9f5f0dcda05c7c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5358d62685d141beb0bd181ac5d3437d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5bf63090bd4103aa37b2e67808e4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be996d6489a45269aa8c93e484248f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75074a0d3cc1444881c0ba3d3093edb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:12:58.077353Z",
     "iopub.status.busy": "2024-12-26T15:12:58.077068Z",
     "iopub.status.idle": "2024-12-26T15:12:58.455513Z",
     "shell.execute_reply": "2024-12-26T15:12:58.454589Z",
     "shell.execute_reply.started": "2024-12-26T15:12:58.077327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:13:01.085592Z",
     "iopub.status.busy": "2024-12-26T15:13:01.085283Z",
     "iopub.status.idle": "2024-12-26T15:13:01.094334Z",
     "shell.execute_reply": "2024-12-26T15:13:01.093516Z",
     "shell.execute_reply.started": "2024-12-26T15:13:01.085563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def encode_labels(labels):\n",
    "    return [\"Yes\" if label == \"Yes\" else \"No\" for label in labels]\n",
    "\n",
    "train_texts = train_data['post'].tolist()\n",
    "train_labels = encode_labels(train_data['is_suicide'].tolist())\n",
    "val_texts = val_data['post'].tolist()\n",
    "val_labels = encode_labels(val_data['is_suicide'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:13:03.048214Z",
     "iopub.status.busy": "2024-12-26T15:13:03.047885Z",
     "iopub.status.idle": "2024-12-26T15:13:03.052775Z",
     "shell.execute_reply": "2024-12-26T15:13:03.051889Z",
     "shell.execute_reply.started": "2024-12-26T15:13:03.048186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_map = {\"No\": 0, \"Yes\": 1}\n",
    "train_indices = [label_map[label] for label in train_labels]\n",
    "val_indices = [label_map[label] for label in val_labels]\n",
    "train_dataset = sDataset(train_texts, train_indices, tokenizer, max_len=512)\n",
    "val_dataset = sDataset(val_texts, val_indices, tokenizer, max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:13:14.375906Z",
     "iopub.status.busy": "2024-12-26T15:13:14.375589Z",
     "iopub.status.idle": "2024-12-26T15:13:14.411321Z",
     "shell.execute_reply": "2024-12-26T15:13:14.410618Z",
     "shell.execute_reply.started": "2024-12-26T15:13:14.375877Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    run_name=\"mental-bert-finetune\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    disable_tqdm=False,\n",
    "    dataloader_num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:13:16.550741Z",
     "iopub.status.busy": "2024-12-26T15:13:16.550467Z",
     "iopub.status.idle": "2024-12-26T15:13:16.554893Z",
     "shell.execute_reply": "2024-12-26T15:13:16.554134Z",
     "shell.execute_reply.started": "2024-12-26T15:13:16.550716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:13:18.993421Z",
     "iopub.status.busy": "2024-12-26T15:13:18.993145Z",
     "iopub.status.idle": "2024-12-26T15:13:19.122116Z",
     "shell.execute_reply": "2024-12-26T15:13:19.121427Z",
     "shell.execute_reply.started": "2024-12-26T15:13:18.993399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T15:13:22.256861Z",
     "iopub.status.busy": "2024-12-26T15:13:22.256574Z",
     "iopub.status.idle": "2024-12-26T15:20:31.371632Z",
     "shell.execute_reply": "2024-12-26T15:20:31.370876Z",
     "shell.execute_reply.started": "2024-12-26T15:13:22.256836Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241226_151323-j5wleac1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/challesvu-ton-duc-thang-university/huggingface/runs/j5wleac1' target=\"_blank\">mental-bert-finetune</a></strong> to <a href='https://wandb.ai/challesvu-ton-duc-thang-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/challesvu-ton-duc-thang-university/huggingface' target=\"_blank\">https://wandb.ai/challesvu-ton-duc-thang-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/challesvu-ton-duc-thang-university/huggingface/runs/j5wleac1' target=\"_blank\">https://wandb.ai/challesvu-ton-duc-thang-university/huggingface/runs/j5wleac1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/960 06:57 < 28:08, 0.45 it/s, Epoch 4/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.656100</td>\n",
       "      <td>0.599610</td>\n",
       "      <td>0.725594</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.678715</td>\n",
       "      <td>0.875648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.542600</td>\n",
       "      <td>0.568560</td>\n",
       "      <td>0.717678</td>\n",
       "      <td>0.750583</td>\n",
       "      <td>0.682203</td>\n",
       "      <td>0.834197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.498500</td>\n",
       "      <td>0.596363</td>\n",
       "      <td>0.704485</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.757962</td>\n",
       "      <td>0.616580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.363800</td>\n",
       "      <td>0.629353</td>\n",
       "      <td>0.720317</td>\n",
       "      <td>0.743961</td>\n",
       "      <td>0.696833</td>\n",
       "      <td>0.797927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=192, training_loss=0.5307507229348024, metrics={'train_runtime': 427.7013, 'train_samples_per_second': 70.891, 'train_steps_per_second': 2.245, 'total_flos': 1595505439703040.0, 'train_loss': 0.5307507229348024, 'epoch': 4.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"mental-roberta-finetune-SDCNL\")\n",
    "tokenizer.save_pretrained(\"mental-bert-finetune-SDCNL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T12:38:53.745795Z",
     "iopub.status.busy": "2024-12-20T12:38:53.745488Z",
     "iopub.status.idle": "2024-12-20T12:38:53.749852Z",
     "shell.execute_reply": "2024-12-20T12:38:53.748871Z",
     "shell.execute_reply.started": "2024-12-20T12:38:53.745773Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T12:10:27.484845Z",
     "iopub.status.busy": "2024-12-20T12:10:27.484566Z",
     "iopub.status.idle": "2024-12-20T12:10:47.526890Z",
     "shell.execute_reply": "2024-12-20T12:10:47.526048Z",
     "shell.execute_reply.started": "2024-12-20T12:10:27.484825Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7256\n",
      "Precision: 0.6787\n",
      "Recall: 0.8756\n",
      "F1 Score: 0.7647\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6341627,
     "sourceId": 10252382,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6340143,
     "sourceId": 10250436,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
